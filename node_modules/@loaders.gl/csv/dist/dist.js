(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else {
		var a = factory();
		for(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];
	}
})(window, function() {
return /******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/bundle.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "../../node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

var g;

// This works in non-strict mode
g = (function() {
	return this;
})();

try {
	// This works if eval is allowed (see CSP)
	g = g || new Function("return this")();
} catch (e) {
	// This works if the window reference is available
	if (typeof window === "object") g = window;
}

// g can still be undefined, but nothing to do about it...
// We return undefined, instead of nothing here, so it's
// easier to handle this case. if(!global) { ...}

module.exports = g;


/***/ }),

/***/ "../tables/src/index.js":
/*!******************************!*\
  !*** ../tables/src/index.js ***!
  \******************************/
/*! exports provided: TableBatchBuilder, RowTableBatch, ColumnarTableBatch, deduceTableSchema, JSONLoader, XMLLoader, AsyncQueue */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _lib_table_table_batch_builder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/table/table-batch-builder */ "../tables/src/lib/table/table-batch-builder.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TableBatchBuilder", function() { return _lib_table_table_batch_builder__WEBPACK_IMPORTED_MODULE_0__["default"]; });

/* harmony import */ var _lib_table_row_table_batch__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/table/row-table-batch */ "../tables/src/lib/table/row-table-batch.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "RowTableBatch", function() { return _lib_table_row_table_batch__WEBPACK_IMPORTED_MODULE_1__["default"]; });

/* harmony import */ var _lib_table_columnar_table_batch__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/table/columnar-table-batch */ "../tables/src/lib/table/columnar-table-batch.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "ColumnarTableBatch", function() { return _lib_table_columnar_table_batch__WEBPACK_IMPORTED_MODULE_2__["default"]; });

/* harmony import */ var _lib_table_schema_utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/table/schema-utils */ "../tables/src/lib/table/schema-utils.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "deduceTableSchema", function() { return _lib_table_schema_utils__WEBPACK_IMPORTED_MODULE_3__["deduceTableSchema"]; });

/* harmony import */ var _json_loader__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./json-loader */ "../tables/src/json-loader.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "JSONLoader", function() { return _json_loader__WEBPACK_IMPORTED_MODULE_4__["default"]; });

/* harmony import */ var _xml_loader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./xml-loader */ "../tables/src/xml-loader.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "XMLLoader", function() { return _xml_loader__WEBPACK_IMPORTED_MODULE_5__["default"]; });

/* harmony import */ var _lib_utils_async_queue__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/utils/async-queue */ "../tables/src/lib/utils/async-queue.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "AsyncQueue", function() { return _lib_utils_async_queue__WEBPACK_IMPORTED_MODULE_6__["default"]; });

// TABLE CATEGORY UTILS





// EXPERIMENTAL MICRO-LOADERS



// EXPERIMENTAL APIs



/***/ }),

/***/ "../tables/src/json-loader.js":
/*!************************************!*\
  !*** ../tables/src/json-loader.js ***!
  \************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
// TODO - deprecated
function parseTextSync(text, options) {
  return JSON.parse(text);
}

/* harmony default export */ __webpack_exports__["default"] = ({
  name: 'JSON',
  extensions: ['json'],
  testText: null,
  parseTextSync
});


/***/ }),

/***/ "../tables/src/lib/table/columnar-table-batch.js":
/*!*******************************************************!*\
  !*** ../tables/src/lib/table/columnar-table-batch.js ***!
  \*******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return ColumnarTableBatch; });
class ColumnarTableBatch {
  constructor(schema, batchSize) {
    this.schema = schema;
    this.batchSize = batchSize;

    this.length = 0;
    this.allocated = 0;
    this.columns = null;
    this.isChunkComplete = false;

    this.reallocateColumns();
  }

  addRow(row) {
    // If user keeps pushing rows beyond batch size, reallocate
    this.reallocateColumns();
    for (const fieldName in row) {
      this.columns[fieldName][this.length] = row[fieldName];
    }
    this.length++;
  }

  // Is this TableBatch full?
  chunkComplete() {
    this.isChunkComplete = true;
  }

  isFull() {
    if (this.batchSize === 'auto') {
      return this.isChunkComplete;
    }
    return this.length >= this.allocated;
  }

  getNormalizedBatch() {
    this.pruneColumns();
    const columns = Array.isArray(this.schema) ? this.columns : {};

    // schema is an array if there're no headers
    // object if there are headers
    // columns should match schema format
    if (!Array.isArray(this.schema)) {
      for (const fieldName in this.schema) {
        const field = this.schema[fieldName];
        columns[field.name] = this.columns[field.index];
      }
    }

    this.columns = null;
    this.isChunkComplete = false;

    return {data: columns, schema: this.schema, length: this.length};
  }

  // HELPERS

  reallocateColumns() {
    if (this.length < this.allocated) {
      return;
    }

    this.allocated = this.allocated > 0 ? (this.allocated *= 2) : this.batchSize;
    this.columns = [];

    for (const fieldName in this.schema) {
      const field = this.schema[fieldName];
      const ArrayType = field.type || Float32Array;
      const oldColumn = this.columns[field.index];

      if (oldColumn && ArrayBuffer.isView(oldColumn)) {
        // Copy the old data to the new array
        const typedArray = new ArrayType(this.allocated);
        typedArray.set(oldColumn);
        this.columns[field.index] = typedArray;
      } else if (oldColumn) {
        // Plain array
        oldColumn.length = this.allocated;
        this.columns[field.index] = oldColumn;
      } else {
        // Create new
        this.columns[field.index] = new ArrayType(this.allocated);
      }
    }
  }

  pruneColumns() {
    this.columns = this.columns.map(column => column.slice(0, this.length));
  }
}


/***/ }),

/***/ "../tables/src/lib/table/row-table-batch.js":
/*!**************************************************!*\
  !*** ../tables/src/lib/table/row-table-batch.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return RowTableBatch; });
class RowTableBatch {
  constructor(schema, batchSize) {
    this.schema = schema;
    this.batchSize = batchSize;
    this.rows = null;
    this.length = 0;
    this.isChunkComplete = false;

    // schema is an array if there're no headers
    // object if there are headers
    if (!Array.isArray(schema)) {
      this._headers = [];
      for (const key in schema) {
        this._headers[schema[key].index] = schema[key].name;
      }
    }
  }

  addRow(row) {
    if (!this.rows) {
      this.rows = new Array(this.batchSize);
      this.length = 0;
    }
    this.rows[this.length] = convertRowToObject(row, this._headers);
    this.length++;
  }

  chunkComplete() {
    this.isChunkComplete = true;
  }

  isFull() {
    if (this.batchSize === 'auto') {
      return this.isChunkComplete && this.length > 0;
    }
    return this.rows && this.length >= this.batchSize;
  }

  getNormalizedBatch() {
    if (this.rows) {
      const rows = this.rows.slice(0, this.length);
      this.rows = null;
      this.isChunkComplete = false;
      return {data: rows, schema: this.schema, length: rows.length};
    }
    return null;
  }
}

function convertRowToObject(row, headers) {
  if (!row) {
    throw new Error('null row');
  }
  if (!Array.isArray(row)) {
    return row;
  }

  if (!headers) {
    return row;
  }
  const result = {};
  for (let i = 0; i < headers.length; i++) {
    result[headers[i]] = row[i];
  }
  return result;
}


/***/ }),

/***/ "../tables/src/lib/table/schema-utils.js":
/*!***********************************************!*\
  !*** ../tables/src/lib/table/schema-utils.js ***!
  \***********************************************/
/*! exports provided: deduceTableSchema */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "deduceTableSchema", function() { return deduceTableSchema; });
// SCHEMA SUPPORT - AUTODEDUCTION

function deduceTableSchema(table, schema = null) {
  const deducedSchema = Array.isArray(table)
    ? deduceSchemaForRowTable(table)
    : deduceSchemaForColumnarTable(table);
  // Deduced schema will fill in missing info from partial options.schema, if provided
  return Object.assign(deducedSchema, schema);
}

function deduceSchemaForColumnarTable(columnarTable) {
  const schema = {};
  for (const field in columnarTable) {
    const column = columnarTable[field];
    // Check if column is typed, if so we are done
    if (ArrayBuffer.isView(column)) {
      schema[field] = column.constructor;
      // else we need data
    } else if (column.length) {
      const value = column[0];
      schema[field] = deduceTypeFromValue(value);
      // TODO - support nested schemas?
    }
    // else we mark as present but unknow
    schema[field] = schema[field] || null;
  }
  return schema;
}

function deduceSchemaForRowTable(rowTable) {
  const schema = {};
  if (rowTable.length) {
    const row = rowTable[0];
    // TODO - Could look at additional rows if nulls in first row
    for (const field in row) {
      const value = row[field];
      schema[field] = deduceTypeFromValue(value);
    }
  }
  return schema;
}

function deduceTypeFromValue(value) {
  if (value instanceof Date) {
    return Date;
  } else if (value instanceof Number) {
    return Float32Array;
  } else if (typeof value === 'string') {
    return String;
  }
  return null;
}


/***/ }),

/***/ "../tables/src/lib/table/table-batch-builder.js":
/*!******************************************************!*\
  !*** ../tables/src/lib/table/table-batch-builder.js ***!
  \******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return TableBatchBuilder; });
const DEFAULT_BATCH_SIZE = 100;

class TableBatchBuilder {
  constructor(TableBatchType, schema, batchSize = DEFAULT_BATCH_SIZE) {
    this.TableBatchType = TableBatchType;
    this.schema = schema;
    this.batchSize = batchSize;
    this.batch = null;
    this.batchCount = 0;
  }

  addRow(row) {
    if (!this.batch) {
      const {TableBatchType} = this;
      this.batch = new TableBatchType(this.schema, this.batchSize);
    }

    this.batch.addRow(row);
  }

  chunkComplete() {
    if (this.batch) {
      this.batch.chunkComplete();
    }
  }

  isFull() {
    return this.batch && this.batch.isFull();
  }

  hasBatch() {
    return Boolean(this.batch);
  }

  getNormalizedBatch() {
    if (this.batch) {
      const normalizedBatch = this.batch.getNormalizedBatch();
      this.batch = null;
      normalizedBatch.count = this.batchCount;
      this.batchCount++;
      return normalizedBatch;
    }
    return null;
  }

  // complete() {
  //   let batch = null;
  //   if (this.batch) {
  //     batch = this.batch;
  //     batch.complete();
  //     this.batch = null;
  //   }
  //   return batch;
  // }
}


/***/ }),

/***/ "../tables/src/lib/utils/async-queue.js":
/*!**********************************************!*\
  !*** ../tables/src/lib/utils/async-queue.js ***!
  \**********************************************/
/*! exports provided: takeAsync, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "takeAsync", function() { return takeAsync; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AsyncQueue; });
// From https://github.com/rauschma/async-iter-demo/tree/master/src under MIT license
// http://2ality.com/2016/10/asynchronous-iteration.html

class ArrayQueue extends Array {
  enqueue(value) {
    // Add at the end
    return this.push(value);
  }
  dequeue() {
    // Remove first element
    return this.shift();
  }
}

/**
 * @returns a Promise for an Array with the elements
 * in `asyncIterable`
 */
async function takeAsync(asyncIterable, count = Infinity) {
  const result = [];
  const iterator = asyncIterable[Symbol.asyncIterator]();
  while (result.length < count) {
    const {value, done} = await iterator.next();
    if (done) {
      break;
    }
    result.push(value);
  }
  return result;
}

class AsyncQueue {
  constructor() {
    // enqueues > dequeues
    this._values = new ArrayQueue();
    // dequeues > enqueues
    this._settlers = new ArrayQueue();
    this._closed = false;
  }

  close() {
    while (this._settlers.length > 0) {
      this._settlers.dequeue().resolve({done: true});
    }
    this._closed = true;
  }

  [Symbol.asyncIterator]() {
    return this;
  }

  enqueue(value) {
    if (this._closed) {
      throw new Error('Closed');
    }

    if (this._settlers.length > 0) {
      if (this._values.length > 0) {
        throw new Error('Illegal internal state');
      }
      const settler = this._settlers.dequeue();
      if (value instanceof Error) {
        settler.reject(value);
      } else {
        settler.resolve({value});
      }
    } else {
      this._values.enqueue(value);
    }
  }

  /**
   * @returns a Promise for an IteratorResult
   */
  next() {
    if (this._values.length > 0) {
      const value = this._values.dequeue();
      if (value instanceof Error) {
        return Promise.reject(value);
      }
      return Promise.resolve({value});
    }

    if (this._closed) {
      if (this._settlers.length > 0) {
        throw new Error('Illegal internal state');
      }
      return Promise.resolve({done: true});
    }
    // Wait for new values to be enqueued
    return new Promise((resolve, reject) => {
      this._settlers.enqueue({resolve, reject});
    });
  }
}


/***/ }),

/***/ "../tables/src/lib/xml/parse-xml.js":
/*!******************************************!*\
  !*** ../tables/src/lib/xml/parse-xml.js ***!
  \******************************************/
/*! exports provided: default, parseXMLSupported */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return parseXML; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "parseXMLSupported", function() { return parseXMLSupported; });
/* global window, DOMParser */
function parseXML(xml) {
  if (window.DOMParser) {
    const xmlDoc = new window.DOMParser().parseFromString(xml, 'application/xml');
    const parseError = isXMLParseError(xmlDoc);
    if (parseError) {
      throw new Error(parseError);
    }
    return xmlDoc;
  }

  if (typeof window.ActiveXObject !== 'undefined') {
    const xmlDoc = new window.ActiveXObject('Microsoft.XMLDOM');
    if (xmlDoc) {
      xmlDoc.async = 'false';
      xmlDoc.loadXML(xml);
      return xmlDoc;
    }
  }

  throw new Error('No XML parser available');
}

function parseXMLSupported() {
  if (typeof window === 'undefined') {
    return false;
  }

  if (window.DOMParser) {
    return true;
  }

  if (typeof window.ActiveXObject !== 'undefined' && new window.ActiveXObject('Microsoft.XMLDOM')) {
    return true;
  }

  return false;
}

// https://stackoverflow.com/questions/11563554/how-do-i-detect-xml-parsing-errors-when-using-javascripts-domparser-in-a-cross
function isXMLParseError(parsedDocument) {
  const parser = new DOMParser();
  const erroneousParse = parser.parseFromString('<', 'text/xml');
  const parsererrorNS = erroneousParse.getElementsByTagName('parsererror')[0].namespaceURI;

  if (parsererrorNS === 'http://www.w3.org/1999/xhtml') {
    // In PhantomJS the parseerror element doesn't seem to have a special namespace,
    // so we are just guessing here :(
    const errorElements = parsedDocument.getElementsByTagName('parsererror');
    return errorElements.length ? errorElements[0].innerHTML : null;
  }

  return parsedDocument.getElementsByTagNameNS(parsererrorNS, 'parsererror').length > 0;
}


/***/ }),

/***/ "../tables/src/xml-loader.js":
/*!***********************************!*\
  !*** ../tables/src/xml-loader.js ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _lib_xml_parse_xml__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/xml/parse-xml */ "../tables/src/lib/xml/parse-xml.js");


const XML_HEADER = '<?xml';

function testText(text) {
  return text.startsWith(XML_HEADER);
}

/* harmony default export */ __webpack_exports__["default"] = ({
  name: 'KML',
  extensions: ['kml'],
  supported: Object(_lib_xml_parse_xml__WEBPACK_IMPORTED_MODULE_0__["parseXMLSupported"])(),
  testText,
  parseTextSync: _lib_xml_parse_xml__WEBPACK_IMPORTED_MODULE_0__["default"],
  browserOnly: true,
  worker: false
});


/***/ }),

/***/ "./src/bundle.js":
/*!***********************!*\
  !*** ./src/bundle.js ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/* WEBPACK VAR INJECTION */(function(global) {/* global window, global */
const moduleExports = __webpack_require__(/*! ./index */ "./src/index.js");
const _global = typeof window === 'undefined' ? global : window;
// @ts-ignore
_global.loaders = _global.loaders || {};
// @ts-ignore
module.exports = Object.assign(_global.loaders, moduleExports);

/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../node_modules/webpack/buildin/global.js */ "../../node_modules/webpack/buildin/global.js")))

/***/ }),

/***/ "./src/csv-loader.js":
/*!***************************!*\
  !*** ./src/csv-loader.js ***!
  \***************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _loaders_gl_tables__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @loaders.gl/tables */ "../tables/src/index.js");
/* harmony import */ var _libs_papaparse__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./libs/papaparse */ "./src/libs/papaparse.js");
/* harmony import */ var _libs_papaparse__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_libs_papaparse__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _lib_async_iterator_streamer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/async-iterator-streamer */ "./src/lib/async-iterator-streamer.js");
// __VERSION__ is injected by babel-plugin-version-inline
/* global __VERSION__ */
/* global TextDecoder */




// @ts-ignore TS2304: Cannot find name '__VERSION__'.
const VERSION =  true ? "2.1.6" : undefined;

const CSVLoader = {
  id: 'csv',
  name: 'CSV',
  version: VERSION,
  extensions: ['csv'],
  mimeType: 'text/csv',
  category: 'table',
  parse: async (arrayBuffer, options) =>
    parseCSVSync(new TextDecoder().decode(arrayBuffer), options),
  parseTextSync: parseCSVSync,
  parseInBatches: parseCSVInBatches,
  testText: null,
  options: {
    csv: {
      TableBatch: _loaders_gl_tables__WEBPACK_IMPORTED_MODULE_0__["RowTableBatch"],
      batchSize: 10
    }
  }
};

/* harmony default export */ __webpack_exports__["default"] = (CSVLoader);

function parseCSVSync(csvText, options) {
  // Apps can call the parse method directly, we so apply default options here
  options = {...CSVLoader.options, ...options};
  options.csv = {...CSVLoader.options.csv, ...options.csv};

  const config = {
    header: hasHeader(csvText, options),
    dynamicTyping: true, // Convert numbers and boolean values in rows from strings
    ...options.csv,
    download: false, // We handle loading, no need for papaparse to do it for us
    error: e => {
      throw new Error(e);
    }
  };

  const result = _libs_papaparse__WEBPACK_IMPORTED_MODULE_1___default.a.parse(csvText, config);
  return result.data;
}

// TODO - support batch size 0 = no batching/single batch?
function parseCSVInBatches(asyncIterator, options) {
  // Apps can call the parse method directly, we so apply default options here
  options = {...CSVLoader.options, ...options};
  options.csv = {...CSVLoader.options.csv, ...options.csv};

  const {batchSize} = options.csv;
  const TableBatchType = options.csv.TableBatch;

  const asyncQueue = new _loaders_gl_tables__WEBPACK_IMPORTED_MODULE_0__["AsyncQueue"]();

  let isFirstRow = true;
  let headerRow = null;
  let tableBatchBuilder = null;
  let schema = null;

  const config = {
    download: false, // We handle loading, no need for papaparse to do it for us
    dynamicTyping: true, // Convert numbers and boolean values in rows from strings
    header: false, // Unfortunately, header detection is not automatic and does not infer types

    // chunk(results, parser) {
    //   // TODO batch before adding to queue.
    //   console.log('Chunk:', results, parser);
    //   asyncQueue.enqueue(results.data);
    // },

    // step is called on every row
    step(results, parser) {
      const row = results.data;

      // Check if we need to save a header row
      if (isFirstRow && !headerRow) {
        const header = options.header === undefined ? isHeaderRow(row) : options.header;
        if (header) {
          headerRow = row;
          return;
        }
      }

      // If first data row, we can deduce the schema
      if (isFirstRow) {
        isFirstRow = false;
        schema = deduceSchema(row, headerRow);
      }

      // Add the row
      tableBatchBuilder =
        tableBatchBuilder || new _loaders_gl_tables__WEBPACK_IMPORTED_MODULE_0__["TableBatchBuilder"](TableBatchType, schema, batchSize);

      tableBatchBuilder.addRow(row);
      // If a batch has been completed, emit it
      if (tableBatchBuilder.isFull()) {
        asyncQueue.enqueue(tableBatchBuilder.getNormalizedBatch());
      }
    },

    // complete is called when all rows have been read
    complete(results, file) {
      // Ensure any final (partial) batch gets emitted
      const batch = tableBatchBuilder.getNormalizedBatch();
      if (batch) {
        asyncQueue.enqueue(batch);
      }
      asyncQueue.close();
    }
  };

  _libs_papaparse__WEBPACK_IMPORTED_MODULE_1___default.a.parse(asyncIterator, config, _lib_async_iterator_streamer__WEBPACK_IMPORTED_MODULE_2__["default"]);

  // TODO - Does it matter if we return asyncIterable or asyncIterator
  // return asyncQueue[Symbol.asyncIterator]();
  return asyncQueue;
}

function isHeaderRow(row) {
  return row.every(value => typeof value === 'string');
}

function hasHeader(csvText, options) {
  if ('header' in options) {
    return options.header;
  }

  let header = false;
  _libs_papaparse__WEBPACK_IMPORTED_MODULE_1___default.a.parse(csvText, {
    download: false,
    dynamicTyping: true,
    step: (results, parser) => {
      const row = results.data;
      header = isHeaderRow(row);
      parser.abort();
    }
  });

  return header;
}

function deduceSchema(row, headerRow) {
  const schema = headerRow ? {} : [];
  for (let i = 0; i < row.length; i++) {
    const columnName = (headerRow && headerRow[i]) || i;
    const value = row[i];
    switch (typeof value) {
      case 'number':
      case 'boolean':
        // TODO - booleans could be handled differently...
        schema[columnName] = {name: String(columnName), index: i, type: Float32Array};
        break;
      case 'string':
      default:
        schema[columnName] = {name: String(columnName), index: i, type: Array};
      // We currently only handle numeric rows
      // TODO we could offer a function to map strings to numbers?
    }
  }
  return schema;
}


/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/*! exports provided: CSVLoader */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _csv_loader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./csv-loader */ "./src/csv-loader.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "CSVLoader", function() { return _csv_loader__WEBPACK_IMPORTED_MODULE_0__["default"]; });




/***/ }),

/***/ "./src/lib/async-iterator-streamer.js":
/*!********************************************!*\
  !*** ./src/lib/async-iterator-streamer.js ***!
  \********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return AsyncIteratorStreamer; });
/* harmony import */ var _libs_papaparse__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../libs/papaparse */ "./src/libs/papaparse.js");
/* harmony import */ var _libs_papaparse__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_libs_papaparse__WEBPACK_IMPORTED_MODULE_0__);
// A custom papaparse `Streamer` for async iterators
// Ideally this can be contributed back to papaparse
// Or papaparse can expose Streamer API so we can extend without forking.

/* eslint-disable no-invalid-this */
/* global TextDecoder */

// Note: papaparse is not an ES6 module

const {ChunkStreamer} = _libs_papaparse__WEBPACK_IMPORTED_MODULE_0___default.a;

function AsyncIteratorStreamer(config) {
  config = config || {};

  ChunkStreamer.call(this, config);

  this.textDecoder = new TextDecoder(this._config.encoding);

  // Implement ChunkStreamer base class methods

  // this.pause = function() {
  //   ChunkStreamer.prototype.pause.apply(this, arguments);
  // };

  // this.resume = function() {
  //   ChunkStreamer.prototype.resume.apply(this, arguments);
  //   this._input.resume();
  // };

  this.stream = async function(asyncIterator) {
    this._input = asyncIterator;

    try {
      // ES2018 version
      // TODO - check for pause and abort flags?
      for await (const chunk of asyncIterator) {
        this.parseChunk(this.getStringChunk(chunk));
      }

      // ES5 VERSION
      // while (true) {
      //   asyncIterator.next().then(function(value) {
      //     if (value.done) {
      //       // finalize iterator?
      //     }
      //   }
      //   const  = await ;
      //   if (done) return total;
      //   total += value.length;
      // }

      this._finished = true;
      this.parseChunk('');
    } catch (error) {
      // Inform ChunkStreamer base class of error
      this._sendError(error);
    }
  };

  this._nextChunk = function nextChunk() {
    // Left empty, as async iterator automatically pulls next chunk
  };

  // HELPER METHODS
  this.getStringChunk = function(chunk) {
    return typeof chunk === 'string' ? chunk : this.textDecoder.decode(chunk, {stream: true});
  };
}

AsyncIteratorStreamer.prototype = Object.create(ChunkStreamer.prototype);
AsyncIteratorStreamer.prototype.constructor = AsyncIteratorStreamer;


/***/ }),

/***/ "./src/libs/papaparse.js":
/*!*******************************!*\
  !*** ./src/libs/papaparse.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports) {

// This is a fork of papaparse
// https://github.com/mholt/PapaParse
/* @license
Papa Parse
v5.0.0-beta.0
https://github.com/mholt/PapaParse
License: MIT
*/
// FORK SUMMARY:
// - Adopt ES6 exports
// - Implement new AsyncIteratorStreamer
// - Remove non Async Iterator streamers (can all be handled by new streamer)
// - Remove unused Worker support (loaders.gl worker system used instead)
// - Remove unused jQuery plugin support

/* eslint-disable */
// @ts-nocheck
var global = (function() {
  // alternative method, similar to `Function('return this')()`
  // but without using `eval` (which is disabled when
  // using Content Security Policy).

  if (typeof self !== 'undefined') {
    return self;
  }
  if (typeof window !== 'undefined') {
    return window;
  }
  if (typeof global !== 'undefined') {
    return global;
  }

  // When running tests none of the above have been defined
  return {};
})();

var IS_PAPA_WORKER = false;

var Papa = {};
module.exports = Papa;
Papa.parse = CsvToJson;
Papa.unparse = JsonToCsv;

Papa.RECORD_SEP = String.fromCharCode(30);
Papa.UNIT_SEP = String.fromCharCode(31);
Papa.BYTE_ORDER_MARK = '\ufeff';
Papa.BAD_DELIMITERS = ['\r', '\n', '"', Papa.BYTE_ORDER_MARK];
Papa.WORKERS_SUPPORTED = false; // !IS_WORKER && !!global.Worker;
Papa.NODE_STREAM_INPUT = 1;

// Configurable chunk sizes for local and remote files, respectively
Papa.LocalChunkSize = 1024 * 1024 * 10; // 10 MB
Papa.RemoteChunkSize = 1024 * 1024 * 5; // 5 MB
Papa.DefaultDelimiter = ','; // Used if not specified and detection fails

// Exposed for testing and development only
Papa.Parser = Parser;
Papa.ParserHandle = ParserHandle;

// BEGIN FORK
Papa.ChunkStreamer = ChunkStreamer;
Papa.StringStreamer = StringStreamer;
/*
Papa.NetworkStreamer = NetworkStreamer;
Papa.FileStreamer = FileStreamer;
Papa.ReadableStreamStreamer = ReadableStreamStreamer;
if (typeof PAPA_BROWSER_CONTEXT === 'undefined') {
  Papa.DuplexStreamStreamer = DuplexStreamStreamer;
}
*/
// END FORK

// BEGIN FORK
// Adds an argument to papa.parse
// function CsvToJson(_input, _config)
function CsvToJson(
  _input,
  _config,
  UserDefinedStreamer // BEGIN FORK
) {
  _config = _config || {};
  var dynamicTyping = _config.dynamicTyping || false;
  if (isFunction(dynamicTyping)) {
    _config.dynamicTypingFunction = dynamicTyping;
    // Will be filled on first row call
    dynamicTyping = {};
  }
  _config.dynamicTyping = dynamicTyping;

  _config.transform = isFunction(_config.transform) ? _config.transform : false;

  if (_config.worker && Papa.WORKERS_SUPPORTED) {
    var w = newWorker();

    w.userStep = _config.step;
    w.userChunk = _config.chunk;
    w.userComplete = _config.complete;
    w.userError = _config.error;

    _config.step = isFunction(_config.step);
    _config.chunk = isFunction(_config.chunk);
    _config.complete = isFunction(_config.complete);
    _config.error = isFunction(_config.error);
    delete _config.worker; // prevent infinite loop

    w.postMessage({
      input: _input,
      config: _config,
      workerId: w.id
    });

    return;
  }

  var streamer = null;
  /*
  if (_input === Papa.NODE_STREAM_INPUT && typeof PAPA_BROWSER_CONTEXT === 'undefined') {
    // create a node Duplex stream for use
    // with .pipe
    streamer = new DuplexStreamStreamer(_config);
    return streamer.getStream();
  } else
  */
  if (typeof _input === 'string') {
    // if (_config.download) streamer = new NetworkStreamer(_config);
    // else
    streamer = new StringStreamer(_config);
  }
  /*
  else if (_input.readable === true && isFunction(_input.read) && isFunction(_input.on)) {
    streamer = new ReadableStreamStreamer(_config);
  } else if ((global.File && _input instanceof File) || _input instanceof Object)
    // ...Safari. (see issue #106)
    streamer = new FileStreamer(_config);
  */

  // BEGIN FORK
  if (!streamer) {
    streamer = new UserDefinedStreamer(_config);
  }
  // END FORK

  return streamer.stream(_input);
}

function JsonToCsv(_input, _config) {
  // Default configuration

  /** whether to surround every datum with quotes */
  var _quotes = false;

  /** whether to write headers */
  var _writeHeader = true;

  /** delimiting character(s) */
  var _delimiter = ',';

  /** newline character(s) */
  var _newline = '\r\n';

  /** quote character */
  var _quoteChar = '"';

  /** escaped quote character, either "" or <config.escapeChar>" */
  var _escapedQuote = _quoteChar + _quoteChar;

  /** whether to skip empty lines */
  var _skipEmptyLines = false;

  /** the columns (keys) we expect when we unparse objects */
  var _columns = null;

  unpackConfig();

  var quoteCharRegex = new RegExp(escapeRegExp(_quoteChar), 'g');

  if (typeof _input === 'string') _input = JSON.parse(_input);

  if (Array.isArray(_input)) {
    if (!_input.length || Array.isArray(_input[0])) return serialize(null, _input, _skipEmptyLines);
    else if (typeof _input[0] === 'object')
      return serialize(_columns || objectKeys(_input[0]), _input, _skipEmptyLines);
  } else if (typeof _input === 'object') {
    if (typeof _input.data === 'string') _input.data = JSON.parse(_input.data);

    if (Array.isArray(_input.data)) {
      if (!_input.fields) _input.fields = _input.meta && _input.meta.fields;

      if (!_input.fields)
        _input.fields = Array.isArray(_input.data[0]) ? _input.fields : objectKeys(_input.data[0]);

      if (!Array.isArray(_input.data[0]) && typeof _input.data[0] !== 'object')
        _input.data = [_input.data]; // handles input like [1,2,3] or ['asdf']
    }

    return serialize(_input.fields || [], _input.data || [], _skipEmptyLines);
  }

  // Default (any valid paths should return before this)
  throw new Error('Unable to serialize unrecognized input');

  function unpackConfig() {
    if (typeof _config !== 'object') return;

    if (
      typeof _config.delimiter === 'string' &&
      !Papa.BAD_DELIMITERS.filter(function(value) {
        return _config.delimiter.indexOf(value) !== -1;
      }).length
    ) {
      _delimiter = _config.delimiter;
    }

    if (typeof _config.quotes === 'boolean' || Array.isArray(_config.quotes))
      _quotes = _config.quotes;

    if (typeof _config.skipEmptyLines === 'boolean' || typeof _config.skipEmptyLines === 'string')
      _skipEmptyLines = _config.skipEmptyLines;

    if (typeof _config.newline === 'string') _newline = _config.newline;

    if (typeof _config.quoteChar === 'string') _quoteChar = _config.quoteChar;

    if (typeof _config.header === 'boolean') _writeHeader = _config.header;

    if (Array.isArray(_config.columns)) {
      if (_config.columns.length === 0) throw new Error('Option columns is empty');

      _columns = _config.columns;
    }

    if (_config.escapeChar !== undefined) {
      _escapedQuote = _config.escapeChar + _quoteChar;
    }
  }

  /** Turns an object's keys into an array */
  function objectKeys(obj) {
    if (typeof obj !== 'object') return [];
    var keys = [];
    for (var key in obj) keys.push(key);
    return keys;
  }

  /** The double for loop that iterates the data and writes out a CSV string including header row */
  function serialize(fields, data, skipEmptyLines) {
    var csv = '';

    if (typeof fields === 'string') fields = JSON.parse(fields);
    if (typeof data === 'string') data = JSON.parse(data);

    var hasHeader = Array.isArray(fields) && fields.length > 0;
    var dataKeyedByField = !Array.isArray(data[0]);

    // If there a header row, write it first
    if (hasHeader && _writeHeader) {
      for (var i = 0; i < fields.length; i++) {
        if (i > 0) csv += _delimiter;
        csv += safe(fields[i], i);
      }
      if (data.length > 0) csv += _newline;
    }

    // Then write out the data
    for (var row = 0; row < data.length; row++) {
      var maxCol = hasHeader ? fields.length : data[row].length;

      var emptyLine = false;
      var nullLine = hasHeader ? Object.keys(data[row]).length === 0 : data[row].length === 0;
      if (skipEmptyLines && !hasHeader) {
        emptyLine =
          skipEmptyLines === 'greedy'
            ? data[row].join('').trim() === ''
            : data[row].length === 1 && data[row][0].length === 0;
      }
      if (skipEmptyLines === 'greedy' && hasHeader) {
        var line = [];
        for (var c = 0; c < maxCol; c++) {
          var cx = dataKeyedByField ? fields[c] : c;
          line.push(data[row][cx]);
        }
        emptyLine = line.join('').trim() === '';
      }
      if (!emptyLine) {
        for (var col = 0; col < maxCol; col++) {
          if (col > 0 && !nullLine) csv += _delimiter;
          var colIdx = hasHeader && dataKeyedByField ? fields[col] : col;
          csv += safe(data[row][colIdx], col);
        }
        if (row < data.length - 1 && (!skipEmptyLines || (maxCol > 0 && !nullLine))) {
          csv += _newline;
        }
      }
    }
    return csv;
  }

  /** Encloses a value around quotes if needed (makes a value safe for CSV insertion) */
  function safe(str, col) {
    if (typeof str === 'undefined' || str === null) return '';

    if (str.constructor === Date) return JSON.stringify(str).slice(1, 25);

    str = str.toString().replace(quoteCharRegex, _escapedQuote);

    var needsQuotes =
      (typeof _quotes === 'boolean' && _quotes) ||
      (Array.isArray(_quotes) && _quotes[col]) ||
      hasAny(str, Papa.BAD_DELIMITERS) ||
      str.indexOf(_delimiter) > -1 ||
      str.charAt(0) === ' ' ||
      str.charAt(str.length - 1) === ' ';

    return needsQuotes ? _quoteChar + str + _quoteChar : str;
  }

  function hasAny(str, substrings) {
    for (var i = 0; i < substrings.length; i++) if (str.indexOf(substrings[i]) > -1) return true;
    return false;
  }
}

/** ChunkStreamer is the base prototype for various streamer implementations. */
function ChunkStreamer(config) {
  this._handle = null;
  this._finished = false;
  this._completed = false;
  this._input = null;
  this._baseIndex = 0;
  this._partialLine = '';
  this._rowCount = 0;
  this._start = 0;
  this._nextChunk = null;
  this.isFirstChunk = true;
  this._completeResults = {
    data: [],
    errors: [],
    meta: {}
  };
  replaceConfig.call(this, config);

  this.parseChunk = function(chunk, isFakeChunk) {
    // First chunk pre-processing
    if (this.isFirstChunk && isFunction(this._config.beforeFirstChunk)) {
      var modifiedChunk = this._config.beforeFirstChunk(chunk);
      if (modifiedChunk !== undefined) chunk = modifiedChunk;
    }
    this.isFirstChunk = false;

    // Rejoin the line we likely just split in two by chunking the file
    var aggregate = this._partialLine + chunk;
    this._partialLine = '';

    var results = this._handle.parse(aggregate, this._baseIndex, !this._finished);

    if (this._handle.paused() || this._handle.aborted()) return;

    var lastIndex = results.meta.cursor;

    if (!this._finished) {
      this._partialLine = aggregate.substring(lastIndex - this._baseIndex);
      this._baseIndex = lastIndex;
    }

    if (results && results.data) this._rowCount += results.data.length;

    var finishedIncludingPreview =
      this._finished || (this._config.preview && this._rowCount >= this._config.preview);

    if (IS_PAPA_WORKER) {
      global.postMessage({
        results: results,
        workerId: Papa.WORKER_ID,
        finished: finishedIncludingPreview
      });
    } else if (isFunction(this._config.chunk) && !isFakeChunk) {
      this._config.chunk(results, this._handle);
      if (this._handle.paused() || this._handle.aborted()) return;
      results = undefined;
      this._completeResults = undefined;
    }

    if (!this._config.step && !this._config.chunk) {
      this._completeResults.data = this._completeResults.data.concat(results.data);
      this._completeResults.errors = this._completeResults.errors.concat(results.errors);
      this._completeResults.meta = results.meta;
    }

    if (
      !this._completed &&
      finishedIncludingPreview &&
      isFunction(this._config.complete) &&
      (!results || !results.meta.aborted)
    ) {
      this._config.complete(this._completeResults, this._input);
      this._completed = true;
    }

    if (!finishedIncludingPreview && (!results || !results.meta.paused)) this._nextChunk();

    return results;
  };

  this._sendError = function(error) {
    if (isFunction(this._config.error)) this._config.error(error);
    else if (IS_PAPA_WORKER && this._config.error) {
      global.postMessage({
        workerId: Papa.WORKER_ID,
        error: error,
        finished: false
      });
    }
  };

  function replaceConfig(config) {
    // Deep-copy the config so we can edit it
    var configCopy = copy(config);
    configCopy.chunkSize = parseInt(configCopy.chunkSize); // parseInt VERY important so we don't concatenate strings!
    if (!config.step && !config.chunk) configCopy.chunkSize = null; // disable Range header if not streaming; bad values break IIS - see issue #196
    this._handle = new ParserHandle(configCopy);
    this._handle.streamer = this;
    this._config = configCopy; // persist the copy to the caller
  }
}

/*
function NetworkStreamer(config) {
  config = config || {};
  if (!config.chunkSize) config.chunkSize = Papa.RemoteChunkSize;
  ChunkStreamer.call(this, config);

  var xhr;

  if (IS_WORKER) {
    this._nextChunk = function() {
      this._readChunk();
      this._chunkLoaded();
    };
  } else {
    this._nextChunk = function() {
      this._readChunk();
    };
  }

  this.stream = function(url) {
    this._input = url;
    this._nextChunk(); // Starts streaming
  };

  this._readChunk = function() {
    if (this._finished) {
      this._chunkLoaded();
      return;
    }

    xhr = new XMLHttpRequest();

    if (this._config.withCredentials) {
      xhr.withCredentials = this._config.withCredentials;
    }

    if (!IS_WORKER) {
      xhr.onload = bindFunction(this._chunkLoaded, this);
      xhr.onerror = bindFunction(this._chunkError, this);
    }

    xhr.open('GET', this._input, !IS_WORKER);
    // Headers can only be set when once the request state is OPENED
    if (this._config.downloadRequestHeaders) {
      var headers = this._config.downloadRequestHeaders;

      for (var headerName in headers) {
        xhr.setRequestHeader(headerName, headers[headerName]);
      }
    }

    if (this._config.chunkSize) {
      var end = this._start + this._config.chunkSize - 1; // minus one because byte range is inclusive
      xhr.setRequestHeader('Range', 'bytes=' + this._start + '-' + end);
    }

    try {
      xhr.send();
    } catch (err) {
      this._chunkError(err.message);
    }

    if (IS_WORKER && xhr.status === 0) this._chunkError();
    else this._start += this._config.chunkSize;
  };

  this._chunkLoaded = function() {
    if (xhr.readyState !== 4) return;

    if (xhr.status < 200 || xhr.status >= 400) {
      this._chunkError();
      return;
    }

    this._finished = !this._config.chunkSize || this._start > getFileSize(xhr);
    this.parseChunk(xhr.responseText);
  };

  this._chunkError = function(errorMessage) {
    var errorText = xhr.statusText || errorMessage;
    this._sendError(new Error(errorText));
  };

  function getFileSize(xhr) {
    var contentRange = xhr.getResponseHeader('Content-Range');
    if (contentRange === null) {
      // no content range, then finish!
      return -1;
    }
    return parseInt(contentRange.substr(contentRange.lastIndexOf('/') + 1));
  }
}
NetworkStreamer.prototype = Object.create(ChunkStreamer.prototype);
NetworkStreamer.prototype.constructor = NetworkStreamer;

function FileStreamer(config) {
  config = config || {};
  if (!config.chunkSize) config.chunkSize = Papa.LocalChunkSize;
  ChunkStreamer.call(this, config);

  var reader, slice;

  // FileReader is better than FileReaderSync (even in worker) - see http://stackoverflow.com/q/24708649/1048862
  // But Firefox is a pill, too - see issue #76: https://github.com/mholt/PapaParse/issues/76
  var usingAsyncReader = typeof FileReader !== 'undefined'; // Safari doesn't consider it a function - see issue #105

  this.stream = function(file) {
    this._input = file;
    slice = file.slice || file.webkitSlice || file.mozSlice;

    if (usingAsyncReader) {
      reader = new FileReader(); // Preferred method of reading files, even in workers
      reader.onload = bindFunction(this._chunkLoaded, this);
      reader.onerror = bindFunction(this._chunkError, this);
    } else reader = new FileReaderSync(); // Hack for running in a web worker in Firefox

    this._nextChunk(); // Starts streaming
  };

  this._nextChunk = function() {
    if (!this._finished && (!this._config.preview || this._rowCount < this._config.preview))
      this._readChunk();
  };

  this._readChunk = function() {
    var input = this._input;
    if (this._config.chunkSize) {
      var end = Math.min(this._start + this._config.chunkSize, this._input.size);
      input = slice.call(input, this._start, end);
    }
    var txt = reader.readAsText(input, this._config.encoding);
    if (!usingAsyncReader) this._chunkLoaded({target: {result: txt}}); // mimic the async signature
  };

  this._chunkLoaded = function(event) {
    // Very important to increment start each time before handling results
    this._start += this._config.chunkSize;
    this._finished = !this._config.chunkSize || this._start >= this._input.size;
    this.parseChunk(event.target.result);
  };

  this._chunkError = function() {
    this._sendError(reader.error);
  };
}
FileStreamer.prototype = Object.create(ChunkStreamer.prototype);
FileStreamer.prototype.constructor = FileStreamer;
*/

function StringStreamer(config) {
  config = config || {};
  ChunkStreamer.call(this, config);

  var remaining;
  this.stream = function(s) {
    remaining = s;
    return this._nextChunk();
  };
  this._nextChunk = function() {
    if (this._finished) return;
    var size = this._config.chunkSize;
    var chunk = size ? remaining.substr(0, size) : remaining;
    remaining = size ? remaining.substr(size) : '';
    this._finished = !remaining;
    return this.parseChunk(chunk);
  };
}
StringStreamer.prototype = Object.create(StringStreamer.prototype);
StringStreamer.prototype.constructor = StringStreamer;

/*
function ReadableStreamStreamer(config) {
  config = config || {};

  ChunkStreamer.call(this, config);

  var queue = [];
  var parseOnData = true;
  var streamHasEnded = false;

  this.pause = function() {
    ChunkStreamer.prototype.pause.apply(this, arguments);
    this._input.pause();
  };

  this.resume = function() {
    ChunkStreamer.prototype.resume.apply(this, arguments);
    this._input.resume();
  };

  this.stream = function(stream) {
    this._input = stream;

    this._input.on('data', this._streamData);
    this._input.on('end', this._streamEnd);
    this._input.on('error', this._streamError);
  };

  this._checkIsFinished = function() {
    if (streamHasEnded && queue.length === 1) {
      this._finished = true;
    }
  };

  this._nextChunk = function() {
    this._checkIsFinished();
    if (queue.length) {
      this.parseChunk(queue.shift());
    } else {
      parseOnData = true;
    }
  };

  this._streamData = bindFunction(function(chunk) {
    try {
      queue.push(typeof chunk === 'string' ? chunk : chunk.toString(this._config.encoding));

      if (parseOnData) {
        parseOnData = false;
        this._checkIsFinished();
        this.parseChunk(queue.shift());
      }
    } catch (error) {
      this._streamError(error);
    }
  }, this);

  this._streamError = bindFunction(function(error) {
    this._streamCleanUp();
    this._sendError(error);
  }, this);

  this._streamEnd = bindFunction(function() {
    this._streamCleanUp();
    streamHasEnded = true;
    this._streamData('');
  }, this);

  this._streamCleanUp = bindFunction(function() {
    this._input.removeListener('data', this._streamData);
    this._input.removeListener('end', this._streamEnd);
    this._input.removeListener('error', this._streamError);
  }, this);
}
ReadableStreamStreamer.prototype = Object.create(ChunkStreamer.prototype);
ReadableStreamStreamer.prototype.constructor = ReadableStreamStreamer;

function DuplexStreamStreamer(_config) {
  var Duplex = require('stream').Duplex;
  var config = copy(_config);
  var parseOnWrite = true;
  var writeStreamHasFinished = false;
  var parseCallbackQueue = [];
  var stream = null;

  this._onCsvData = function(results) {
    var data = results.data;
    if (!stream.push(data) && !this._handle.paused()) {
      // the writeable consumer buffer has filled up
      // so we need to pause until more items
      // can be processed
      this._handle.pause();
    }
  };

  this._onCsvComplete = function() {
    // node will finish the read stream when
    // null is pushed
    stream.push(null);
  };

  config.step = bindFunction(this._onCsvData, this);
  config.complete = bindFunction(this._onCsvComplete, this);
  ChunkStreamer.call(this, config);

  this._nextChunk = function() {
    if (writeStreamHasFinished && parseCallbackQueue.length === 1) {
      this._finished = true;
    }
    if (parseCallbackQueue.length) {
      parseCallbackQueue.shift()();
    } else {
      parseOnWrite = true;
    }
  };

  this._addToParseQueue = function(chunk, callback) {
    // add to queue so that we can indicate
    // completion via callback
    // node will automatically pause the incoming stream
    // when too many items have been added without their
    // callback being invoked
    parseCallbackQueue.push(
      bindFunction(function() {
        this.parseChunk(typeof chunk === 'string' ? chunk : chunk.toString(config.encoding));
        if (isFunction(callback)) {
          return callback();
        }
      }, this)
    );
    if (parseOnWrite) {
      parseOnWrite = false;
      this._nextChunk();
    }
  };

  this._onRead = function() {
    if (this._handle.paused()) {
      // the writeable consumer can handle more data
      // so resume the chunk parsing
      this._handle.resume();
    }
  };

  this._onWrite = function(chunk, encoding, callback) {
    this._addToParseQueue(chunk, callback);
  };

  this._onWriteComplete = function() {
    writeStreamHasFinished = true;
    // have to write empty string
    // so parser knows its done
    this._addToParseQueue('');
  };

  this.getStream = function() {
    return stream;
  };
  stream = new Duplex({
    readableObjectMode: true,
    decodeStrings: false,
    read: bindFunction(this._onRead, this),
    write: bindFunction(this._onWrite, this)
  });
  stream.once('finish', bindFunction(this._onWriteComplete, this));
}
if (typeof PAPA_BROWSER_CONTEXT === 'undefined') {
  DuplexStreamStreamer.prototype = Object.create(ChunkStreamer.prototype);
  DuplexStreamStreamer.prototype.constructor = DuplexStreamStreamer;
}
*/

// Use one ParserHandle per entire CSV file or string
function ParserHandle(_config) {
  // One goal is to minimize the use of regular expressions...
  var FLOAT = /^\s*-?(\d*\.?\d+|\d+\.?\d*)(e[-+]?\d+)?\s*$/i;
  var ISO_DATE = /(\d{4}-[01]\d-[0-3]\dT[0-2]\d:[0-5]\d:[0-5]\d\.\d+([+-][0-2]\d:[0-5]\d|Z))|(\d{4}-[01]\d-[0-3]\dT[0-2]\d:[0-5]\d:[0-5]\d([+-][0-2]\d:[0-5]\d|Z))|(\d{4}-[01]\d-[0-3]\dT[0-2]\d:[0-5]\d([+-][0-2]\d:[0-5]\d|Z))/;

  var self = this;
  var _stepCounter = 0; // Number of times step was called (number of rows parsed)
  var _rowCounter = 0; // Number of rows that have been parsed so far
  var _input; // The input being parsed
  var _parser; // The core parser being used
  var _paused = false; // Whether we are paused or not
  var _aborted = false; // Whether the parser has aborted or not
  var _delimiterError; // Temporary state between delimiter detection and processing results
  var _fields = []; // Fields are from the header row of the input, if there is one
  var _results = {
    // The last results returned from the parser
    data: [],
    errors: [],
    meta: {}
  };

  if (isFunction(_config.step)) {
    var userStep = _config.step;
    _config.step = function(results) {
      _results = results;

      if (needsHeaderRow()) processResults();
      // only call user's step function after header row
      else {
        processResults();

        // It's possbile that this line was empty and there's no row here after all
        if (_results.data.length === 0) return;

        _stepCounter += results.data.length;
        if (_config.preview && _stepCounter > _config.preview) _parser.abort();
        else userStep(_results, self);
      }
    };
  }

  /**
   * Parses input. Most users won't need, and shouldn't mess with, the baseIndex
   * and ignoreLastRow parameters. They are used by streamers (wrapper functions)
   * when an input comes in multiple chunks, like from a file.
   */
  this.parse = function(input, baseIndex, ignoreLastRow) {
    var quoteChar = _config.quoteChar || '"';
    if (!_config.newline) _config.newline = guessLineEndings(input, quoteChar);

    _delimiterError = false;
    if (!_config.delimiter) {
      var delimGuess = guessDelimiter(
        input,
        _config.newline,
        _config.skipEmptyLines,
        _config.comments,
        _config.delimitersToGuess
      );
      if (delimGuess.successful) _config.delimiter = delimGuess.bestDelimiter;
      else {
        _delimiterError = true; // add error after parsing (otherwise it would be overwritten)
        _config.delimiter = Papa.DefaultDelimiter;
      }
      _results.meta.delimiter = _config.delimiter;
    } else if (isFunction(_config.delimiter)) {
      _config.delimiter = _config.delimiter(input);
      _results.meta.delimiter = _config.delimiter;
    }

    var parserConfig = copy(_config);
    if (_config.preview && _config.header) parserConfig.preview++; // to compensate for header row

    _input = input;
    _parser = new Parser(parserConfig);
    _results = _parser.parse(_input, baseIndex, ignoreLastRow);
    processResults();
    return _paused ? {meta: {paused: true}} : _results || {meta: {paused: false}};
  };

  this.paused = function() {
    return _paused;
  };

  this.pause = function() {
    _paused = true;
    _parser.abort();
    _input = _input.substr(_parser.getCharIndex());
  };

  this.resume = function() {
    _paused = false;
    self.streamer.parseChunk(_input, true);
  };

  this.aborted = function() {
    return _aborted;
  };

  this.abort = function() {
    _aborted = true;
    _parser.abort();
    _results.meta.aborted = true;
    if (isFunction(_config.complete)) _config.complete(_results);
    _input = '';
  };

  function testEmptyLine(s) {
    return _config.skipEmptyLines === 'greedy'
      ? s.join('').trim() === ''
      : s.length === 1 && s[0].length === 0;
  }

  function processResults() {
    if (_results && _delimiterError) {
      addError(
        'Delimiter',
        'UndetectableDelimiter',
        "Unable to auto-detect delimiting character; defaulted to '" + Papa.DefaultDelimiter + "'"
      );
      _delimiterError = false;
    }

    if (_config.skipEmptyLines) {
      for (var i = 0; i < _results.data.length; i++)
        if (testEmptyLine(_results.data[i])) _results.data.splice(i--, 1);
    }

    if (needsHeaderRow()) fillHeaderFields();

    return applyHeaderAndDynamicTypingAndTransformation();
  }

  function needsHeaderRow() {
    return _config.header && _fields.length === 0;
  }

  function fillHeaderFields() {
    if (!_results) return;

    function addHeder(header) {
      if (isFunction(_config.transformHeader)) header = _config.transformHeader(header);

      _fields.push(header);
    }

    if (Array.isArray(_results.data[0])) {
      for (var i = 0; needsHeaderRow() && i < _results.data.length; i++)
        _results.data[i].forEach(addHeder);

      _results.data.splice(0, 1);
    }
    // if _results.data[0] is not an array, we are in a step where _results.data is the row.
    else _results.data.forEach(addHeder);
  }

  function shouldApplyDynamicTyping(field) {
    // Cache function values to avoid calling it for each row
    if (_config.dynamicTypingFunction && _config.dynamicTyping[field] === undefined) {
      _config.dynamicTyping[field] = _config.dynamicTypingFunction(field);
    }
    return (_config.dynamicTyping[field] || _config.dynamicTyping) === true;
  }

  function parseDynamic(field, value) {
    if (shouldApplyDynamicTyping(field)) {
      if (value === 'true' || value === 'TRUE') return true;
      else if (value === 'false' || value === 'FALSE') return false;
      else if (FLOAT.test(value)) return parseFloat(value);
      else if (ISO_DATE.test(value)) return new Date(value);
      else return value === '' ? null : value;
    }
    return value;
  }

  function applyHeaderAndDynamicTypingAndTransformation() {
    if (!_results || (!_config.header && !_config.dynamicTyping && !_config.transform))
      return _results;

    function processRow(rowSource, i) {
      var row = _config.header ? {} : [];

      var j;
      for (j = 0; j < rowSource.length; j++) {
        var field = j;
        var value = rowSource[j];

        if (_config.header) field = j >= _fields.length ? '__parsed_extra' : _fields[j];

        if (_config.transform) value = _config.transform(value, field);

        value = parseDynamic(field, value);

        if (field === '__parsed_extra') {
          row[field] = row[field] || [];
          row[field].push(value);
        } else row[field] = value;
      }

      if (_config.header) {
        if (j > _fields.length)
          addError(
            'FieldMismatch',
            'TooManyFields',
            'Too many fields: expected ' + _fields.length + ' fields but parsed ' + j,
            _rowCounter + i
          );
        else if (j < _fields.length)
          addError(
            'FieldMismatch',
            'TooFewFields',
            'Too few fields: expected ' + _fields.length + ' fields but parsed ' + j,
            _rowCounter + i
          );
      }

      return row;
    }

    var incrementBy = 1;
    if (!_results.data[0] || Array.isArray(_results.data[0])) {
      _results.data = _results.data.map(processRow);
      incrementBy = _results.data.length;
    } else _results.data = processRow(_results.data, 0);

    if (_config.header && _results.meta) _results.meta.fields = _fields;

    _rowCounter += incrementBy;
    return _results;
  }

  function guessDelimiter(input, newline, skipEmptyLines, comments, delimitersToGuess) {
    var bestDelim, bestDelta, fieldCountPrevRow;

    delimitersToGuess = delimitersToGuess || [',', '\t', '|', ';', Papa.RECORD_SEP, Papa.UNIT_SEP];

    for (var i = 0; i < delimitersToGuess.length; i++) {
      var delim = delimitersToGuess[i];
      var delta = 0,
        avgFieldCount = 0,
        emptyLinesCount = 0;
      fieldCountPrevRow = undefined;

      var preview = new Parser({
        comments: comments,
        delimiter: delim,
        newline: newline,
        preview: 10
      }).parse(input);

      for (var j = 0; j < preview.data.length; j++) {
        if (skipEmptyLines && testEmptyLine(preview.data[j])) {
          emptyLinesCount++;
          continue;
        }
        var fieldCount = preview.data[j].length;
        avgFieldCount += fieldCount;

        if (typeof fieldCountPrevRow === 'undefined') {
          fieldCountPrevRow = 0;
          continue;
        } else if (fieldCount > 1) {
          delta += Math.abs(fieldCount - fieldCountPrevRow);
          fieldCountPrevRow = fieldCount;
        }
      }

      if (preview.data.length > 0) avgFieldCount /= preview.data.length - emptyLinesCount;

      if ((typeof bestDelta === 'undefined' || delta > bestDelta) && avgFieldCount > 1.99) {
        bestDelta = delta;
        bestDelim = delim;
      }
    }

    _config.delimiter = bestDelim;

    return {
      successful: !!bestDelim,
      bestDelimiter: bestDelim
    };
  }

  function guessLineEndings(input, quoteChar) {
    input = input.substr(0, 1024 * 1024); // max length 1 MB
    // Replace all the text inside quotes
    var re = new RegExp(escapeRegExp(quoteChar) + '([^]*?)' + escapeRegExp(quoteChar), 'gm');
    input = input.replace(re, '');

    var r = input.split('\r');

    var n = input.split('\n');

    var nAppearsFirst = n.length > 1 && n[0].length < r[0].length;

    if (r.length === 1 || nAppearsFirst) return '\n';

    var numWithN = 0;
    for (var i = 0; i < r.length; i++) {
      if (r[i][0] === '\n') numWithN++;
    }

    return numWithN >= r.length / 2 ? '\r\n' : '\r';
  }

  function addError(type, code, msg, row) {
    _results.errors.push({
      type: type,
      code: code,
      message: msg,
      row: row
    });
  }
}

/** https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions */
function escapeRegExp(string) {
  return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'); // $& means the whole matched string
}

/** The core parser implements speedy and correct CSV parsing */
function Parser(config) {
  // Unpack the config object
  config = config || {};
  var delim = config.delimiter;
  var newline = config.newline;
  var comments = config.comments;
  var step = config.step;
  var preview = config.preview;
  var fastMode = config.fastMode;
  var quoteChar;
  /** Allows for no quoteChar by setting quoteChar to undefined in config */
  if (config.quoteChar === undefined) {
    quoteChar = '"';
  } else {
    quoteChar = config.quoteChar;
  }
  var escapeChar = quoteChar;
  if (config.escapeChar !== undefined) {
    escapeChar = config.escapeChar;
  }

  // Delimiter must be valid
  if (typeof delim !== 'string' || Papa.BAD_DELIMITERS.indexOf(delim) > -1) delim = ',';

  // Comment character must be valid
  if (comments === delim) throw new Error('Comment character same as delimiter');
  else if (comments === true) comments = '#';
  else if (typeof comments !== 'string' || Papa.BAD_DELIMITERS.indexOf(comments) > -1)
    comments = false;

  // Newline must be valid: \r, \n, or \r\n
  if (newline !== '\n' && newline !== '\r' && newline !== '\r\n') newline = '\n';

  // We're gonna need these at the Parser scope
  var cursor = 0;
  var aborted = false;

  this.parse = function(input, baseIndex, ignoreLastRow) {
    // For some reason, in Chrome, this speeds things up (!?)
    if (typeof input !== 'string') throw new Error('Input must be a string');

    // We don't need to compute some of these every time parse() is called,
    // but having them in a more local scope seems to perform better
    var inputLen = input.length,
      delimLen = delim.length,
      newlineLen = newline.length,
      commentsLen = comments.length;
    var stepIsFunction = isFunction(step);

    // Establish starting state
    cursor = 0;
    var data = [],
      errors = [],
      row = [],
      lastCursor = 0;

    if (!input) return returnable();

    if (fastMode || (fastMode !== false && input.indexOf(quoteChar) === -1)) {
      var rows = input.split(newline);
      for (var i = 0; i < rows.length; i++) {
        row = rows[i];
        cursor += row.length;
        if (i !== rows.length - 1) cursor += newline.length;
        else if (ignoreLastRow) return returnable();
        if (comments && row.substr(0, commentsLen) === comments) continue;
        if (stepIsFunction) {
          data = [];
          pushRow(row.split(delim));
          doStep();
          if (aborted) return returnable();
        } else pushRow(row.split(delim));
        if (preview && i >= preview) {
          data = data.slice(0, preview);
          return returnable(true);
        }
      }
      return returnable();
    }

    var nextDelim = input.indexOf(delim, cursor);
    var nextNewline = input.indexOf(newline, cursor);
    var quoteCharRegex = new RegExp(escapeRegExp(escapeChar) + escapeRegExp(quoteChar), 'g');
    var quoteSearch;

    // Parser loop
    for (;;) {
      // Field has opening quote
      if (input[cursor] === quoteChar) {
        // Start our search for the closing quote where the cursor is
        quoteSearch = cursor;

        // Skip the opening quote
        cursor++;

        for (;;) {
          // Find closing quote
          quoteSearch = input.indexOf(quoteChar, quoteSearch + 1);

          //No other quotes are found - no other delimiters
          if (quoteSearch === -1) {
            if (!ignoreLastRow) {
              // No closing quote... what a pity
              errors.push({
                type: 'Quotes',
                code: 'MissingQuotes',
                message: 'Quoted field unterminated',
                row: data.length, // row has yet to be inserted
                index: cursor
              });
            }
            return finish();
          }

          // Closing quote at EOF
          if (quoteSearch === inputLen - 1) {
            var value = input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar);
            return finish(value);
          }

          // If this quote is escaped, it's part of the data; skip it
          // If the quote character is the escape character, then check if the next character is the escape character
          if (quoteChar === escapeChar && input[quoteSearch + 1] === escapeChar) {
            quoteSearch++;
            continue;
          }

          // If the quote character is not the escape character, then check if the previous character was the escape character
          if (
            quoteChar !== escapeChar &&
            quoteSearch !== 0 &&
            input[quoteSearch - 1] === escapeChar
          ) {
            continue;
          }

          // Check up to nextDelim or nextNewline, whichever is closest
          var checkUpTo = nextNewline === -1 ? nextDelim : Math.min(nextDelim, nextNewline);
          var spacesBetweenQuoteAndDelimiter = extraSpaces(checkUpTo);

          // Closing quote followed by delimiter or 'unnecessary spaces + delimiter'
          if (input[quoteSearch + 1 + spacesBetweenQuoteAndDelimiter] === delim) {
            row.push(input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar));
            cursor = quoteSearch + 1 + spacesBetweenQuoteAndDelimiter + delimLen;
            nextDelim = input.indexOf(delim, cursor);
            nextNewline = input.indexOf(newline, cursor);
            break;
          }

          var spacesBetweenQuoteAndNewLine = extraSpaces(nextNewline);

          // Closing quote followed by newline or 'unnecessary spaces + newLine'
          if (
            input.substr(quoteSearch + 1 + spacesBetweenQuoteAndNewLine, newlineLen) === newline
          ) {
            row.push(input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar));
            saveRow(quoteSearch + 1 + spacesBetweenQuoteAndNewLine + newlineLen);
            nextDelim = input.indexOf(delim, cursor); // because we may have skipped the nextDelim in the quoted field

            if (stepIsFunction) {
              doStep();
              if (aborted) return returnable();
            }

            if (preview && data.length >= preview) return returnable(true);

            break;
          }

          // Checks for valid closing quotes are complete (escaped quotes or quote followed by EOF/delimiter/newline) -- assume these quotes are part of an invalid text string
          errors.push({
            type: 'Quotes',
            code: 'InvalidQuotes',
            message: 'Trailing quote on quoted field is malformed',
            row: data.length, // row has yet to be inserted
            index: cursor
          });

          quoteSearch++;
          continue;
        }

        continue;
      }

      // Comment found at start of new line
      if (comments && row.length === 0 && input.substr(cursor, commentsLen) === comments) {
        if (nextNewline === -1)
          // Comment ends at EOF
          return returnable();
        cursor = nextNewline + newlineLen;
        nextNewline = input.indexOf(newline, cursor);
        nextDelim = input.indexOf(delim, cursor);
        continue;
      }

      // Next delimiter comes before next newline, so we've reached end of field
      if (nextDelim !== -1 && (nextDelim < nextNewline || nextNewline === -1)) {
        row.push(input.substring(cursor, nextDelim));
        cursor = nextDelim + delimLen;
        nextDelim = input.indexOf(delim, cursor);
        continue;
      }

      // End of row
      if (nextNewline !== -1) {
        row.push(input.substring(cursor, nextNewline));
        saveRow(nextNewline + newlineLen);

        if (stepIsFunction) {
          doStep();
          if (aborted) return returnable();
        }

        if (preview && data.length >= preview) return returnable(true);

        continue;
      }

      break;
    }

    return finish();

    function pushRow(row) {
      data.push(row);
      lastCursor = cursor;
    }

    /**
     * checks if there are extra spaces after closing quote and given index without any text
     * if Yes, returns the number of spaces
     */
    function extraSpaces(index) {
      var spaceLength = 0;
      if (index !== -1) {
        var textBetweenClosingQuoteAndIndex = input.substring(quoteSearch + 1, index);
        if (textBetweenClosingQuoteAndIndex && textBetweenClosingQuoteAndIndex.trim() === '') {
          spaceLength = textBetweenClosingQuoteAndIndex.length;
        }
      }
      return spaceLength;
    }

    /**
     * Appends the remaining input from cursor to the end into
     * row, saves the row, calls step, and returns the results.
     */
    function finish(value) {
      if (ignoreLastRow) return returnable();
      if (typeof value === 'undefined') value = input.substr(cursor);
      row.push(value);
      cursor = inputLen; // important in case parsing is paused
      pushRow(row);
      if (stepIsFunction) doStep();
      return returnable();
    }

    /**
     * Appends the current row to the results. It sets the cursor
     * to newCursor and finds the nextNewline. The caller should
     * take care to execute user's step function and check for
     * preview and end parsing if necessary.
     */
    function saveRow(newCursor) {
      cursor = newCursor;
      pushRow(row);
      row = [];
      nextNewline = input.indexOf(newline, cursor);
    }

    /** Returns an object with the results, errors, and meta. */
    function returnable(stopped, step) {
      var isStep = step || false;
      return {
        data: isStep ? data[0] : data,
        errors: errors,
        meta: {
          delimiter: delim,
          linebreak: newline,
          aborted: aborted,
          truncated: !!stopped,
          cursor: lastCursor + (baseIndex || 0)
        }
      };
    }

    /** Executes the user's step function and resets data & errors. */
    function doStep() {
      step(returnable(undefined, true));
      data = [];
      errors = [];
    }
  };

  /** Sets the abort flag */
  this.abort = function() {
    aborted = true;
  };

  /** Gets the cursor position */
  this.getCharIndex = function() {
    return cursor;
  };
}

/*
function getWorkerBlob() {
	var URL = global.URL || global.webkitURL || null;
	var code = moduleFactory.toString();
	return Papa.BLOB_URL || (Papa.BLOB_URL = URL.createObjectURL(new Blob(['(', code, ')();'], {type: 'text/javascript'})));
}

var IS_WORKER = !global.document && !!global.postMessage,
	IS_PAPA_WORKER = IS_WORKER && /blob:/i.test((global.location || {}).protocol);
var workers = {}, workerIdCounter = 0;

function newWorker()
{
	if (!Papa.WORKERS_SUPPORTED)
		return false;

	var workerUrl = getWorkerBlob();
	var w = new global.Worker(workerUrl);
	w.onmessage = mainThreadReceivedMessage;
	w.id = workerIdCounter++;
	workers[w.id] = w;
	return w;
}

// Callback when main thread receives a message
function mainThreadReceivedMessage(e)
{
	var msg = e.data;
	var worker = workers[msg.workerId];
	var aborted = false;

	if (msg.error)
		worker.userError(msg.error, msg.file);
	else if (msg.results && msg.results.data)
	{
		var abort = function() {
			aborted = true;
			completeWorker(msg.workerId, { data: [], errors: [], meta: { aborted: true } });
		};

		var handle = {
			abort: abort,
			pause: notImplemented,
			resume: notImplemented
		};

		if (isFunction(worker.userStep))
		{
			for (var i = 0; i < msg.results.data.length; i++)
			{
				worker.userStep({
					data: msg.results.data[i],
					errors: msg.results.errors,
					meta: msg.results.meta
				}, handle);
				if (aborted)
					break;
			}
			delete msg.results;	// free memory ASAP
		}
		else if (isFunction(worker.userChunk))
		{
			worker.userChunk(msg.results, handle, msg.file);
			delete msg.results;
		}
	}

	if (msg.finished && !aborted)
		completeWorker(msg.workerId, msg.results);
}

function completeWorker(workerId, results) {
	var worker = workers[workerId];
	if (isFunction(worker.userComplete))
		worker.userComplete(results);
	worker.terminate();
	delete workers[workerId];
}

// Callback when worker thread receives a message
function workerThreadReceivedMessage(e)
{
	var msg = e.data;

	if (typeof Papa.WORKER_ID === 'undefined' && msg)
		Papa.WORKER_ID = msg.workerId;

	if (typeof msg.input === 'string')
	{
		global.postMessage({
			workerId: Papa.WORKER_ID,
			results: Papa.parse(msg.input, msg.config),
			finished: true
		});
	}
	else if ((global.File && msg.input instanceof File) || msg.input instanceof Object)	// thank you, Safari (see issue #106)
	{
		var results = Papa.parse(msg.input, msg.config);
		if (results)
			global.postMessage({
				workerId: Papa.WORKER_ID,
				results: results,
				finished: true
			});
	}
}
*/

function notImplemented() {
  throw new Error('Not implemented.');
}

/** Makes a deep copy of an array or object (mostly) */
function copy(obj) {
  if (typeof obj !== 'object' || obj === null) return obj;
  var cpy = Array.isArray(obj) ? [] : {};
  for (var key in obj) cpy[key] = copy(obj[key]);
  return cpy;
}

function bindFunction(f, self) {
  return function() {
    f.apply(self, arguments);
  };
}

function isFunction(func) {
  return typeof func === 'function';
}


/***/ })

/******/ });
});